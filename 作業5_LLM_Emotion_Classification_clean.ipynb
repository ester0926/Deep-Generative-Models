{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ester0926/Deep-Generative-Models/blob/main/%E4%BD%9C%E6%A5%AD5_LLM_Emotion_Classification_clean.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EAciQo-DGdmD"
      },
      "outputs": [],
      "source": [
        "!pip install -q datasets transformers peft accelerate evaluate bitsandbytes scikit-learn matplotlib seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "465pTUydGdmE"
      },
      "outputs": [],
      "source": [
        "# 載入套件\n",
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        "    AutoModelForSequenceClassification,\n",
        "    pipeline,\n",
        "    BitsAndBytesConfig,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        ")\n",
        "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training, TaskType\n",
        "import evaluate\n",
        "from sklearn.metrics import (\n",
        "    f1_score,\n",
        "    accuracy_score,\n",
        "    roc_auc_score,\n",
        "    precision_recall_curve,\n",
        "    auc,\n",
        "    confusion_matrix,\n",
        "    ConfusionMatrixDisplay,\n",
        "    classification_report\n",
        ")\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import gc\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mo4ljkP1GdmF"
      },
      "outputs": [],
      "source": [
        "# 作業設定\n",
        "# 模型選擇（符合作業要求：TinyLlama、LLaMA、Qwen、Mistral）\n",
        "MODEL_NAME = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"  # 1.1B，適合免費 Colab\n",
        "\n",
        "# 資料集設定\n",
        "MAX_LENGTH = 128\n",
        "TRAIN_SAMPLES = 2000  # 從 16,000 中選取\n",
        "VAL_SAMPLES = 500     # 從 2,000 中選取\n",
        "TEST_SAMPLES = 500    # 從 2,000 中選取\n",
        "\n",
        "# 風險標註（Risk Mapping）\n",
        "LABEL_TO_EMOTION = {\n",
        "    0: \"sadness\", 1: \"joy\", 2: \"love\",\n",
        "    3: \"anger\", 4: \"fear\", 5: \"surprise\"\n",
        "}\n",
        "\n",
        "# joy/love/surprise → 0 = low_risk\n",
        "# anger/fear → 1 = mid_risk\n",
        "# sadness → 2 = high_risk\n",
        "EMOTION_TO_RISK = {\n",
        "    \"joy\": 0, \"love\": 0, \"surprise\": 0,\n",
        "    \"anger\": 1, \"fear\": 1,\n",
        "    \"sadness\": 2\n",
        "}\n",
        "\n",
        "EMOTIONS_LIST = [\"sadness\", \"joy\", \"love\", \"anger\", \"fear\", \"surprise\"]\n",
        "\n",
        "print(f\"✅ 使用模型: {MODEL_NAME}\")\n",
        "print(f\"✅ 訓練樣本: {TRAIN_SAMPLES} | 驗證樣本: {VAL_SAMPLES} | 測試樣本: {TEST_SAMPLES}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YOPtDtaLGdmF"
      },
      "outputs": [],
      "source": [
        "# 資料載入\n",
        "dataset = load_dataset(\"dair-ai/emotion\")\n",
        "\n",
        "# 建立風險映射\n",
        "def map_to_risk(example):\n",
        "    emotion_name = LABEL_TO_EMOTION[example[\"label\"]]\n",
        "    example[\"risk\"] = EMOTION_TO_RISK[emotion_name]\n",
        "    return example\n",
        "\n",
        "dataset = dataset.map(map_to_risk)\n",
        "\n",
        "print(f\"\\n資料集統計:\")\n",
        "print(f\"  訓練集: {len(dataset['train'])} 筆\")\n",
        "print(f\"  驗證集: {len(dataset['validation'])} 筆\")\n",
        "print(f\"  測試集: {len(dataset['test'])} 筆\")\n",
        "\n",
        "# 情緒標籤分布\n",
        "print(f\"\\n情緒標籤分布:\")\n",
        "emotion_counts = pd.Series([ex['label'] for ex in dataset['train']]).value_counts().sort_index()\n",
        "for label_id, count in emotion_counts.items():\n",
        "    emotion = LABEL_TO_EMOTION[label_id]\n",
        "    risk = EMOTION_TO_RISK[emotion]\n",
        "    print(f\"  {emotion:10s} (risk={risk}): {count:5d} 筆\")\n",
        "\n",
        "# 準備測試集\n",
        "test_data = dataset[\"test\"].select(range(TEST_SAMPLES))\n",
        "test_texts = [ex[\"text\"] for ex in test_data]\n",
        "test_labels = [ex[\"label\"] for ex in test_data]\n",
        "\n",
        "print(f\"\\n範例文本:\")\n",
        "for i in range(3):\n",
        "    sample = dataset['train'][i]\n",
        "    emotion = LABEL_TO_EMOTION[sample['label']]\n",
        "    risk = EMOTION_TO_RISK[emotion]\n",
        "    print(f\"  [{emotion}, risk={risk}] {sample['text'][:60]}...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p2XFH8mHGdmF"
      },
      "outputs": [],
      "source": [
        "# 輔助函數\n",
        "def show_examples(texts, true_labels, predictions, method_name, n=10):\n",
        "    \"\"\"顯示預測範例\"\"\"\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"{method_name} - 預測範例 (前 {n} 個)\")\n",
        "    print(f\"{'='*80}\")\n",
        "    print(f\"{'No.':<4} {'True':<12} {'Pred':<12} {'Match':<6} {'Text':<50}\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    for i in range(min(n, len(texts))):\n",
        "        true_emotion = LABEL_TO_EMOTION[true_labels[i]]\n",
        "        pred_emotion = LABEL_TO_EMOTION[predictions[i]]\n",
        "        match = \"✓\" if true_emotion == pred_emotion else \"✗\"\n",
        "        text_preview = texts[i][:47] + \"...\" if len(texts[i]) > 47 else texts[i]\n",
        "\n",
        "        print(f\"{i+1:<4} {true_emotion:<12} {pred_emotion:<12} {match:<6} {text_preview}\")\n",
        "\n",
        "def calculate_metrics(y_true, y_pred, method_name):\n",
        "    \"\"\"計算評估指標\"\"\"\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred, average=\"weighted\")\n",
        "\n",
        "    print(f\"\\n【{method_name} 評估指標】\")\n",
        "    print(f\"  Accuracy: {acc:.4f}\")\n",
        "    print(f\"  F1 Score (weighted): {f1:.4f}\")\n",
        "\n",
        "    # 計算 AUROC (多分類 one-vs-rest)\n",
        "    try:\n",
        "        y_true_onehot = pd.get_dummies(y_true).values\n",
        "        y_pred_onehot = pd.get_dummies(y_pred).values\n",
        "        auroc = roc_auc_score(y_true_onehot, y_pred_onehot, average=\"weighted\", multi_class=\"ovr\")\n",
        "        print(f\"  AUROC (weighted): {auroc:.4f}\")\n",
        "    except:\n",
        "        print(f\"  AUROC: N/A (無法計算)\")\n",
        "\n",
        "    return {\"accuracy\": acc, \"f1\": f1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VruWVaKWGdmG"
      },
      "outputs": [],
      "source": [
        "# 方法 1: Zero-shot\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"【方法 1: Zero-shot 推論】\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\n載入 TinyLlama 模型...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "generator = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=MODEL_NAME,\n",
        "    tokenizer=tokenizer,\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=torch.float16,\n",
        ")\n",
        "\n",
        "def zero_shot_predict(text, generator):\n",
        "    \"\"\"Zero-shot 情緒分類\"\"\"\n",
        "    prompt = f\"\"\"<|system|>\n",
        "You are an emotion classifier. Classify the text into one of these emotions: sadness, joy, love, anger, fear, surprise.\n",
        "<|user|>\n",
        "Text: \"{text}\"\n",
        "Emotion:<|assistant|>\n",
        "\"\"\"\n",
        "\n",
        "    try:\n",
        "        result = generator(\n",
        "            prompt,\n",
        "            max_new_tokens=10,\n",
        "            temperature=0.3,\n",
        "            do_sample=True,\n",
        "            return_full_text=False,\n",
        "            pad_token_id=tokenizer.eos_token_id\n",
        "        )[0][\"generated_text\"]\n",
        "\n",
        "        result_lower = result.lower().strip()\n",
        "\n",
        "        for emotion in EMOTIONS_LIST:\n",
        "            if emotion in result_lower:\n",
        "                return emotion\n",
        "\n",
        "        # Fallback: 關鍵字匹配\n",
        "        text_lower = text.lower()\n",
        "        if any(word in text_lower for word in [\"hate\", \"angry\", \"mad\"]):\n",
        "            return \"anger\"\n",
        "        elif any(word in text_lower for word in [\"happy\", \"glad\", \"excited\"]):\n",
        "            return \"joy\"\n",
        "        elif any(word in text_lower for word in [\"sad\", \"depressed\", \"down\"]):\n",
        "            return \"sadness\"\n",
        "        elif any(word in text_lower for word in [\"love\", \"adore\"]):\n",
        "            return \"love\"\n",
        "        elif any(word in text_lower for word in [\"fear\", \"scared\", \"afraid\"]):\n",
        "            return \"fear\"\n",
        "        else:\n",
        "            return \"surprise\"\n",
        "\n",
        "    except:\n",
        "        return \"joy\"\n",
        "\n",
        "print(\"\\n開始 Zero-shot 預測...\")\n",
        "zero_shot_predictions = []\n",
        "for text in tqdm(test_texts, desc=\"Zero-shot\"):\n",
        "    pred = zero_shot_predict(text, generator)\n",
        "    if pred not in EMOTIONS_LIST:\n",
        "        pred = \"joy\"\n",
        "    pred_label = [k for k, v in LABEL_TO_EMOTION.items() if v == pred][0]\n",
        "    zero_shot_predictions.append(pred_label)\n",
        "\n",
        "zero_results = calculate_metrics(test_labels, zero_shot_predictions, \"Zero-shot\")\n",
        "show_examples(test_texts, test_labels, zero_shot_predictions, \"Zero-shot\", n=10)\n",
        "\n",
        "# 釋放記憶體\n",
        "del generator\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XSMD7-pdGdmG"
      },
      "outputs": [],
      "source": [
        "# 方法 2: Few-shot\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"【方法 2: Few-shot 推論】\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\n重新載入模型...\")\n",
        "generator = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=MODEL_NAME,\n",
        "    tokenizer=tokenizer,\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=torch.float16,\n",
        ")\n",
        "\n",
        "def few_shot_predict(text, generator):\n",
        "    prompt = f\"\"\"Classify emotions:\n",
        "\n",
        "\"I'm so happy!\" → joy\n",
        "\"I feel empty.\" → sadness\n",
        "\"I love this!\" → love\n",
        "\n",
        "\"{text}\" →\"\"\"\n",
        "\n",
        "    try:\n",
        "        result = generator(\n",
        "            prompt,\n",
        "            max_new_tokens=2,      # ← 只需 1-2 個 token\n",
        "            temperature=0.01,       # ← 幾乎沒有隨機性\n",
        "            do_sample=False,        # ← 完全確定性\n",
        "            return_full_text=False,\n",
        "            pad_token_id=tokenizer.eos_token_id\n",
        "        )[0][\"generated_text\"]\n",
        "\n",
        "        result_lower = result.lower().strip()\n",
        "\n",
        "        for emotion in EMOTIONS_LIST:\n",
        "            if emotion in result_lower:\n",
        "                return emotion\n",
        "\n",
        "        # Fallback\n",
        "        # ... (同之前)\n",
        "\n",
        "    except:\n",
        "        return \"joy\"\n",
        "\n",
        "print(\"\\n開始 Few-shot 預測...\")\n",
        "few_shot_predictions = []\n",
        "for text in tqdm(test_texts, desc=\"Few-shot\"):\n",
        "    pred = few_shot_predict(text, generator)\n",
        "    if pred not in EMOTIONS_LIST:\n",
        "        pred = \"joy\"\n",
        "    pred_label = [k for k, v in LABEL_TO_EMOTION.items() if v == pred][0]\n",
        "    few_shot_predictions.append(pred_label)\n",
        "\n",
        "few_results = calculate_metrics(test_labels, few_shot_predictions, \"Few-shot\")\n",
        "show_examples(test_texts, test_labels, few_shot_predictions, \"Few-shot\", n=10)\n",
        "\n",
        "# 釋放記憶體\n",
        "del generator\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YSEwKCgqGdmG"
      },
      "outputs": [],
      "source": [
        "# 方法 3: LoRA Fine-tuning\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"【方法 3: LoRA 微調】\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\n載入分類模型...\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    num_labels=6,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "# LoRA 配置\n",
        "lora_config = LoraConfig(\n",
        "    r=8,\n",
        "    lora_alpha=16,\n",
        "    target_modules=[\"q_proj\", \"v_proj\"],\n",
        "    lora_dropout=0.1,\n",
        "    bias=\"none\",\n",
        "    task_type=TaskType.SEQ_CLS\n",
        ")\n",
        "\n",
        "model = prepare_model_for_kbit_training(model)\n",
        "model = get_peft_model(model, lora_config)\n",
        "\n",
        "print(\"\\n模型參數統計:\")\n",
        "model.print_trainable_parameters()\n",
        "\n",
        "# 資料預處理\n",
        "def preprocess_function(examples):\n",
        "    return tokenizer(\n",
        "        examples[\"text\"],\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=MAX_LENGTH\n",
        "    )\n",
        "\n",
        "print(\"\\n預處理資料...\")\n",
        "tokenized_datasets = dataset.map(\n",
        "    preprocess_function,\n",
        "    batched=True,\n",
        "    remove_columns=[\"text\", \"risk\"]\n",
        ")\n",
        "\n",
        "train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(TRAIN_SAMPLES))\n",
        "val_dataset = tokenized_datasets[\"validation\"].select(range(VAL_SAMPLES))\n",
        "test_dataset = tokenized_datasets[\"test\"].select(range(TEST_SAMPLES))\n",
        "\n",
        "# 訓練設定\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=3,\n",
        "    learning_rate=2e-4,\n",
        "    weight_decay=0.01,\n",
        "    logging_steps=100,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1\",\n",
        "    report_to=\"none\",\n",
        "    fp16=True,\n",
        ")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions = np.argmax(eval_pred.predictions, axis=1)\n",
        "    labels = eval_pred.label_ids\n",
        "    acc = accuracy_score(labels, predictions)\n",
        "    f1 = f1_score(labels, predictions, average=\"weighted\")\n",
        "    return {\"accuracy\": acc, \"f1\": f1}\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "print(\"\\n開始訓練...\")\n",
        "trainer.train()\n",
        "\n",
        "# 評估\n",
        "print(\"\\n評估 LoRA 模型...\")\n",
        "predictions = trainer.predict(test_dataset)\n",
        "lora_predictions = np.argmax(predictions.predictions, axis=1)\n",
        "\n",
        "lora_results = calculate_metrics(test_labels, lora_predictions, \"LoRA Fine-tuning\")\n",
        "show_examples(test_texts, test_labels, lora_predictions, \"LoRA\", n=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fw-6Dc7iGdmH"
      },
      "outputs": [],
      "source": [
        "# 三種方法比較\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"【三種方法性能比較】\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "results_df = pd.DataFrame({\n",
        "    \"Method\": [\"Zero-shot\", \"Few-shot\", \"LoRA Fine-tuning\"],\n",
        "    \"Accuracy\": [\n",
        "        zero_results[\"accuracy\"],\n",
        "        few_results[\"accuracy\"],\n",
        "        lora_results[\"accuracy\"]\n",
        "    ],\n",
        "    \"F1 Score\": [\n",
        "        zero_results[\"f1\"],\n",
        "        few_results[\"f1\"],\n",
        "        lora_results[\"f1\"]\n",
        "    ]\n",
        "})\n",
        "\n",
        "print(\"\\n\" + results_df.to_string(index=False))\n",
        "\n",
        "print(f\"\\n改進幅度:\")\n",
        "print(f\"  Few-shot vs Zero-shot: {(few_results['f1'] - zero_results['f1'])/zero_results['f1']*100:+.1f}%\")\n",
        "print(f\"  LoRA vs Few-shot: {(lora_results['f1'] - few_results['f1'])/few_results['f1']*100:+.1f}%\")\n",
        "print(f\"  LoRA vs Zero-shot: {(lora_results['f1'] - zero_results['f1'])/zero_results['f1']*100:+.1f}%\")\n",
        "\n",
        "# 詳細分類報告\n",
        "print(\"\\n【詳細分類報告】\")\n",
        "for name, preds in [(\"Zero-shot\", zero_shot_predictions),\n",
        "                     (\"Few-shot\", few_shot_predictions),\n",
        "                     (\"LoRA\", lora_predictions)]:\n",
        "    print(f\"\\n{name}:\")\n",
        "    print(classification_report(test_labels, preds, target_names=EMOTIONS_LIST, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LLPrp9qnGdmH"
      },
      "outputs": [],
      "source": [
        "# 視覺化比較\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"【評估與視覺化】\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "fig = plt.figure(figsize=(18, 12))\n",
        "gs = fig.add_gridspec(3, 3, hspace=0.35, wspace=0.3)\n",
        "\n",
        "# 1. 性能比較\n",
        "ax1 = fig.add_subplot(gs[0, :])\n",
        "x = np.arange(len(results_df))\n",
        "width = 0.35\n",
        "bars1 = ax1.bar(x - width/2, results_df[\"Accuracy\"], width, label='Accuracy', alpha=0.8)\n",
        "bars2 = ax1.bar(x + width/2, results_df[\"F1 Score\"], width, label='F1 Score', alpha=0.8)\n",
        "ax1.set_xlabel('Method', fontsize=12, fontweight='bold')\n",
        "ax1.set_ylabel('Score', fontsize=12)\n",
        "ax1.set_title('Performance Comparison', fontsize=14, fontweight='bold')\n",
        "ax1.set_xticks(x)\n",
        "ax1.set_xticklabels(results_df[\"Method\"])\n",
        "ax1.legend()\n",
        "ax1.set_ylim(0, 1.0)\n",
        "ax1.grid(axis='y', alpha=0.3)\n",
        "\n",
        "for bars in [bars1, bars2]:\n",
        "    for bar in bars:\n",
        "        height = bar.get_height()\n",
        "        ax1.text(bar.get_x() + bar.get_width()/2., height,\n",
        "                f'{height:.3f}', ha='center', va='bottom', fontsize=9)\n",
        "\n",
        "# 2-4. 混淆矩陣\n",
        "for idx, (name, preds, pos) in enumerate([\n",
        "    (\"Zero-shot\", zero_shot_predictions, gs[1, 0]),\n",
        "    (\"Few-shot\", few_shot_predictions, gs[1, 1]),\n",
        "    (\"LoRA\", lora_predictions, gs[1, 2])\n",
        "]):\n",
        "    ax = fig.add_subplot(pos)\n",
        "    cm = confusion_matrix(test_labels, preds)\n",
        "    im = ax.imshow(cm, cmap='Blues', aspect='auto')\n",
        "    ax.set_xticks(np.arange(6))\n",
        "    ax.set_yticks(np.arange(6))\n",
        "    ax.set_xticklabels(EMOTIONS_LIST, rotation=45, ha='right', fontsize=8)\n",
        "    ax.set_yticklabels(EMOTIONS_LIST, fontsize=8)\n",
        "\n",
        "    for i in range(6):\n",
        "        for j in range(6):\n",
        "            ax.text(j, i, f'{cm[i, j]}', ha=\"center\", va=\"center\",\n",
        "                   color=\"white\" if cm[i, j] > cm.max()/2 else \"black\", fontsize=8)\n",
        "\n",
        "    ax.set_title(f'{name} Confusion Matrix', fontsize=11, fontweight='bold')\n",
        "    ax.set_xlabel('Predicted')\n",
        "    ax.set_ylabel('True')\n",
        "\n",
        "# 5-6. 風險分析\n",
        "ax5 = fig.add_subplot(gs[2, :2])\n",
        "\n",
        "risk_scores = {}\n",
        "for name, preds in [(\"Zero\", zero_shot_predictions),\n",
        "                     (\"Few\", few_shot_predictions),\n",
        "                     (\"LoRA\", lora_predictions)]:\n",
        "    risks = [EMOTION_TO_RISK[LABEL_TO_EMOTION[p]] for p in preds]\n",
        "    risk_scores[name] = risks\n",
        "    ax5.plot(risks, label=name, alpha=0.7, linewidth=1.5)\n",
        "\n",
        "ax5.axhline(y=1.5, color='red', linestyle='--', linewidth=2, label='High Risk Threshold')\n",
        "ax5.set_title('Risk Trend Comparison', fontsize=12, fontweight='bold')\n",
        "ax5.set_xlabel('Sample Index')\n",
        "ax5.set_ylabel('Risk Level (0=Low, 1=Mid, 2=High)')\n",
        "ax5.legend()\n",
        "ax5.grid(alpha=0.3)\n",
        "\n",
        "# 7. 熱力圖\n",
        "ax6 = fig.add_subplot(gs[2, 2])\n",
        "lora_risks = risk_scores[\"LoRA\"]\n",
        "if len(lora_risks) >= 100:\n",
        "    rows, cols = 10, 10\n",
        "    risk_matrix = np.array(lora_risks[:rows*cols]).reshape(rows, cols)\n",
        "    sns.heatmap(risk_matrix, cmap=\"Reds\", cbar_kws={'label': 'Risk'}, ax=ax6, vmin=0, vmax=2)\n",
        "    ax6.set_title('LoRA Risk Heatmap', fontsize=11, fontweight='bold')\n",
        "\n",
        "plt.savefig('hw5_results.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pD4QnpCYGdmH"
      },
      "outputs": [],
      "source": [
        "# 憂鬱風險分析比較\n",
        "print(\"\\n【風險監測統計】\")\n",
        "\n",
        "true_risks = [EMOTION_TO_RISK[LABEL_TO_EMOTION[l]] for l in test_labels]\n",
        "\n",
        "for name, preds in [(\"Zero-shot\", zero_shot_predictions),\n",
        "                     (\"Few-shot\", few_shot_predictions),\n",
        "                     (\"LoRA\", lora_predictions)]:\n",
        "    pred_risks = [EMOTION_TO_RISK[LABEL_TO_EMOTION[p]] for p in preds]\n",
        "    risk_acc = sum([1 for p, t in zip(pred_risks, true_risks) if p == t]) / len(pred_risks)\n",
        "\n",
        "    print(f\"\\n{name}:\")\n",
        "    print(f\"  風險分類準確率: {risk_acc*100:.2f}%\")\n",
        "\n",
        "    risk_counts = pd.Series(pred_risks).value_counts().sort_index()\n",
        "    print(f\"  低風險 (0): {risk_counts.get(0, 0)} 個\")\n",
        "    print(f\"  中風險 (1): {risk_counts.get(1, 0)} 個\")\n",
        "    print(f\"  高風險 (2): {risk_counts.get(2, 0)} 個\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"✅ 作業完成！\")\n",
        "print(\"=\"*80)\n",
        "print(\"\\n生成檔案:\")\n",
        "print(\"  - hw5_results.png (完整評估圖表)\")\n",
        "print(f\"\\n最佳方法: LoRA Fine-tuning (F1: {lora_results['f1']:.4f})\")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}